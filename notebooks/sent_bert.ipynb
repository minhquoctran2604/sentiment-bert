{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6UdRPR3mgrt",
        "outputId": "36a37658-4ad7-4557-a041-04a0846fb7f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Uninstalled!\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall -y transformers sentence-transformers torch torchvision torchaudio accelerate datasets -q\n",
        "print(\"âœ“ Uninstalled!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-H2DVdDncX_",
        "outputId": "f74e4099-2268-471f-c8a7-022b4e57bbe0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m780.4/780.4 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "peft 0.18.0 requires accelerate>=0.21.0, which is not installed.\n",
            "peft 0.18.0 requires transformers, which is not installed.\n",
            "torchtune 0.6.1 requires datasets, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m511.6/511.6 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m380.9/380.9 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hâœ“ Installed!\n",
            "\n",
            "âš ï¸ BÃ‚Y GIá»œ ÄI RESTART RUNTIME!\n",
            "Runtime â†’ Restart runtime\n"
          ]
        }
      ],
      "source": [
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 -q\n",
        "!pip install transformers datasets accelerate scikit-learn -q\n",
        "print(\"âœ“ Installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "in-XkG3upVF9",
        "outputId": "c443cd52-0ca1-4a0d-d3c6-b162349d3e61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch: 2.5.1+cu121\n",
            "Transformers: 4.57.3\n",
            "âœ“ Import OK!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import torch\n",
        "import transformers\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"Transformers: {transformers.__version__}\")\n",
        "\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "print(\"âœ“ Import OK!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lNs8mjkRr0vR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUgClWRNqPeN",
        "outputId": "04d1a500-bf01-49ba-c9ef-27bef3aa7288"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-12-11 14:13:42.786460: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765462422.806558   11374 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765462422.813387   11374 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765462422.829900   11374 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765462422.829945   11374 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765462422.829950   11374 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765462422.829954   11374 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "============================================================\n",
            "SENTIMENT ANALYSIS - DOMAIN ADAPTATION\n",
            "SST-2 (movie critics) â†’ IMDB (user reviews)\n",
            "============================================================\n",
            "Generating train split: 100% 25000/25000 [00:00<00:00, 105443.23 examples/s]\n",
            "Generating test split: 100% 25000/25000 [00:00<00:00, 125226.73 examples/s]\n",
            "Generating unsupervised split: 100% 50000/50000 [00:00<00:00, 100042.46 examples/s]\n",
            "Train: 25,000, Test: 25,000\n",
            "Map: 100% 25000/25000 [00:25<00:00, 983.07 examples/s] \n",
            "Map: 100% 25000/25000 [00:24<00:00, 1008.33 examples/s]\n",
            "Map: 100% 50000/50000 [00:48<00:00, 1028.18 examples/s]\n",
            " Train subset: 1000\n",
            " Test subset: 200\n",
            "\n",
            "Loading distilbert-base-uncased-finetuned-sst-2-english...\n",
            "âœ“ Model loaded: 66,955,010 parameters\n",
            "\n",
            "Setting up trainer...\n",
            "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
            "/content/drive/MyDrive/sentiment-bert/src/trainer.py:34: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "Trainer initialized\n",
            "\n",
            "Training configuration:\n",
            "  - Learning rate: 1e-05\n",
            "  - Epochs: 2\n",
            "  - Batch size: 8\n",
            "  - Warmup ratio: 0.1\n",
            "\n",
            "============================================================\n",
            "STARTING TRAINING\n",
            "============================================================\n",
            "\n",
            "{'loss': 0.5146, 'grad_norm': 30.9193115234375, 'learning_rate': 8.933333333333333e-06, 'epoch': 0.4}\n",
            "{'loss': 0.3257, 'grad_norm': 31.504241943359375, 'learning_rate': 6.711111111111111e-06, 'epoch': 0.8}\n",
            " 50% 125/250 [00:45<00:45,  2.76it/s]\n",
            "  0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 2/25 [00:00<00:01, 18.31it/s]\u001b[A\n",
            " 16% 4/25 [00:00<00:01, 11.65it/s]\u001b[A\n",
            " 24% 6/25 [00:00<00:01, 10.34it/s]\u001b[A\n",
            " 32% 8/25 [00:00<00:01,  9.78it/s]\u001b[A\n",
            " 40% 10/25 [00:00<00:01,  9.54it/s]\u001b[A\n",
            " 44% 11/25 [00:01<00:01,  9.48it/s]\u001b[A\n",
            " 48% 12/25 [00:01<00:01,  9.39it/s]\u001b[A\n",
            " 52% 13/25 [00:01<00:01,  9.32it/s]\u001b[A\n",
            " 56% 14/25 [00:01<00:01,  9.30it/s]\u001b[A\n",
            " 60% 15/25 [00:01<00:01,  9.20it/s]\u001b[A\n",
            " 64% 16/25 [00:01<00:00,  9.23it/s]\u001b[A\n",
            " 68% 17/25 [00:01<00:00,  9.23it/s]\u001b[A\n",
            " 72% 18/25 [00:01<00:00,  9.19it/s]\u001b[A\n",
            " 76% 19/25 [00:01<00:00,  9.22it/s]\u001b[A\n",
            " 80% 20/25 [00:02<00:00,  9.18it/s]\u001b[A\n",
            " 84% 21/25 [00:02<00:00,  9.20it/s]\u001b[A\n",
            " 88% 22/25 [00:02<00:00,  9.23it/s]\u001b[A\n",
            " 92% 23/25 [00:02<00:00,  9.22it/s]\u001b[A\n",
            " 96% 24/25 [00:02<00:00,  9.21it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3559337854385376, 'eval_accuracy': 0.86, 'eval_f1': 0.8541666666666666, 'eval_runtime': 2.7548, 'eval_samples_per_second': 72.6, 'eval_steps_per_second': 9.075, 'epoch': 1.0}\n",
            " 50% 125/250 [00:48<00:45,  2.76it/s]\n",
            "100% 25/25 [00:02<00:00,  9.31it/s]\u001b[A\n",
            "{'loss': 0.2142, 'grad_norm': 11.714744567871094, 'learning_rate': 4.488888888888889e-06, 'epoch': 1.2}\n",
            "{'loss': 0.263, 'grad_norm': 1.3799667358398438, 'learning_rate': 2.266666666666667e-06, 'epoch': 1.6}\n",
            "{'loss': 0.1413, 'grad_norm': 5.9552321434021, 'learning_rate': 4.444444444444445e-08, 'epoch': 2.0}\n",
            "100% 250/250 [01:38<00:00,  2.70it/s]\n",
            "  0% 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "  8% 2/25 [00:00<00:01, 18.12it/s]\u001b[A\n",
            " 16% 4/25 [00:00<00:01, 11.60it/s]\u001b[A\n",
            " 24% 6/25 [00:00<00:01, 10.26it/s]\u001b[A\n",
            " 32% 8/25 [00:00<00:01,  9.71it/s]\u001b[A\n",
            " 40% 10/25 [00:00<00:01,  9.46it/s]\u001b[A\n",
            " 44% 11/25 [00:01<00:01,  9.37it/s]\u001b[A\n",
            " 48% 12/25 [00:01<00:01,  9.36it/s]\u001b[A\n",
            " 52% 13/25 [00:01<00:01,  9.36it/s]\u001b[A\n",
            " 56% 14/25 [00:01<00:01,  9.23it/s]\u001b[A\n",
            " 60% 15/25 [00:01<00:01,  9.23it/s]\u001b[A\n",
            " 64% 16/25 [00:01<00:00,  9.08it/s]\u001b[A\n",
            " 68% 17/25 [00:01<00:00,  9.09it/s]\u001b[A\n",
            " 72% 18/25 [00:01<00:00,  9.03it/s]\u001b[A\n",
            " 76% 19/25 [00:01<00:00,  9.11it/s]\u001b[A\n",
            " 80% 20/25 [00:02<00:00,  9.15it/s]\u001b[A\n",
            " 84% 21/25 [00:02<00:00,  9.13it/s]\u001b[A\n",
            " 88% 22/25 [00:02<00:00,  9.16it/s]\u001b[A\n",
            " 92% 23/25 [00:02<00:00,  9.10it/s]\u001b[A\n",
            " 96% 24/25 [00:02<00:00,  9.15it/s]\u001b[A\n",
            "                                     \n",
            "\u001b[A{'eval_loss': 0.3510582745075226, 'eval_accuracy': 0.895, 'eval_f1': 0.8864864864864865, 'eval_runtime': 2.7464, 'eval_samples_per_second': 72.822, 'eval_steps_per_second': 9.103, 'epoch': 2.0}\n",
            "100% 250/250 [01:41<00:00,  2.70it/s]\n",
            "100% 25/25 [00:02<00:00,  9.20it/s]\u001b[A\n",
            "{'train_runtime': 109.1775, 'train_samples_per_second': 18.319, 'train_steps_per_second': 2.29, 'train_loss': 0.2917615509033203, 'epoch': 2.0}\n",
            "100% 250/250 [01:49<00:00,  2.29it/s]\n",
            "\n",
            "============================================================\n",
            "EVALUATING\n",
            "============================================================\n",
            "100% 25/25 [00:02<00:00,  9.12it/s]\n",
            "\n",
            "FINAL RESULTS:\n",
            "  Accuracy: 89.50%\n",
            "  F1 Score: 0.8865\n",
            "  Loss: 0.3511\n",
            "\n",
            "Saving model...\n",
            "âœ“ Model saved to /content/drive/MyDrive/sentiment-bert/models/best_model\n",
            "\n",
            "============================================================\n",
            "TRAINING COMPLETE! ğŸ‰\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/sentiment-bert/scripts/train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "2g9cP5kSy7_G",
        "outputId": "ca6288e8-d5d2-44d0-e2fd-c321683154ea"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_af0ac0c6-11a8-4d66-8246-9588820fed9d\", \"best_model.zip\", 247308579)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ“ Downloading best_model.zip...\n"
          ]
        }
      ],
      "source": [
        "# Cell: Zip & Download model\n",
        "import shutil\n",
        "\n",
        "# Zip model\n",
        "shutil.make_archive('/content/best_model', 'zip', '/content/drive/MyDrive/sentiment-bert/models/best_model')\n",
        "\n",
        "# Download\n",
        "from google.colab import files\n",
        "files.download('/content/best_model.zip')\n",
        "\n",
        "print(\"âœ“ Downloading best_model.zip...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9998728036880493}]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"../models/best_model\", framework=\"pt\")  \n",
        "\n",
        "result = classifier(\"I loved this movie!\")\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
